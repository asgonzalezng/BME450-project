# -*- coding: utf-8 -*-
"""BME450-Glaucomaniacs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TuAoXQVaFjfuszs49G-Zyb4REu8kHduw

Third and hopefully final? iteration of code that will hopefully also display image results.
"""

# glaucoma_diagnosis_ml.py (UPDATED: 80% Train / 20% Validation Split)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import transforms, models
from sklearn.metrics import classification_report
import pandas as pd
import matplotlib.pyplot as plt
import os
from PIL import Image
import numpy as np
from collections import Counter
import random

# ==== CONFIGURATION ====
BATCH_SIZE = 8
NUM_EPOCHS = 40
LEARNING_RATE = 1e-6
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==== DATA TRANSFORMATIONS ====
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(25),
    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ==== CUSTOM DATASET CLASS ====
class FundusDataset(Dataset):
    def __init__(self, expert_dir, labels_dir, transform=None):
        self.expert_dir = expert_dir
        self.labels_dir = labels_dir
        self.transform = transform
        self.samples = self._prepare_samples()

    def _prepare_samples(self):
        samples = []
        for eye_side, excel_file in zip(['OD', 'OS'], ['patient_data_od.xlsx', 'patient_data_os.xlsx']):
            df = pd.read_excel(os.path.join(self.labels_dir, excel_file))
            for i, row in df.iterrows():
                diagnosis = row['Diagnosis']
                if pd.isna(diagnosis) or diagnosis == 2:
                    continue
                label = 0 if diagnosis == 0 else 1
                filename = f"Opht_cont_RET{i+1:03d}{eye_side}.jpg"
                img_path = os.path.join(self.expert_dir, filename)
                if os.path.exists(img_path):
                    samples.append((img_path, label))
        print("Contoured Label counts:", Counter([lbl for _, lbl in samples]))
        return samples

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        raw_image = image.copy()
        if self.transform:
            image = self.transform(image)
        return image, label, raw_image, os.path.basename(img_path)

# ==== CUSTOM COLLATE FUNCTIONS ====
def collate_fn_train(batch):
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    images = torch.stack(images, dim=0)
    labels = torch.tensor(labels)
    return images, labels

def collate_fn_eval(batch):
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    raw_imgs = [item[2] for item in batch]
    filenames = [item[3] for item in batch]
    images = torch.stack(images, dim=0)
    labels = torch.tensor(labels)
    return images, labels, raw_imgs, filenames

# ==== DATASET LOADING ====
full_dataset = FundusDataset(
    expert_dir="/content/ExpertSegmentations",
    labels_dir="/content/ClinicalData",
    transform=transform
)

print(f"Total contoured samples: {len(full_dataset)}")

# Split 80% train, 20% validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_train)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_eval)

# ==== MODEL ARCHITECTURES ====
def get_model(model_name="resnet18"):
    if model_name == "resnet18":
        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        for name, param in model.named_parameters():
            if "layer4" in name or "fc" in name:
                param.requires_grad = True
            else:
                param.requires_grad = False
        model.fc = nn.Linear(model.fc.in_features, 2)
    elif model_name == "efficientnet_b0":
        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)
        for name, param in model.named_parameters():
            if "features.6" in name or "classifier.1" in name:
                param.requires_grad = True
            else:
                param.requires_grad = False
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)
    else:
        raise ValueError("Unsupported model architecture")
    return model.to(DEVICE)

# ==== TRAINING FUNCTION ====
def train_model(model, optimizer, criterion, loader):
    model.train()
    running_loss = 0
    for images, labels in loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    return running_loss / len(loader)

# ==== EVALUATION FUNCTION ====
def evaluate_model(model, loader, show_images=False):
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    display_data = []
    with torch.no_grad():
        for images, labels, raw_imgs, filenames in loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            display_data.append((raw_imgs[0], filenames[0], preds.item(), labels.item()))
    accuracy = 100 * correct / total
    if show_images:
        print("\nPrediction results on validation set:")
        for i, (img, fname, pred, true) in enumerate(display_data):
            plt.imshow(img)
            plt.axis('off')
            plt.title(f"{fname}: Predicted={pred}, Actual={true}, {'✅' if pred==true else '❌'}")
            plt.show()
    return accuracy, all_labels, all_preds

# ==== MAIN TRAINING AND EVALUATION ====
for model_name in ["resnet18", "efficientnet_b0"]:
    print(f"\nTraining {model_name.upper()} on contoured images (80% train)...")
    model = get_model(model_name)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    weights = torch.tensor([1.0, 2.0]).to(DEVICE)
    criterion = nn.CrossEntropyLoss(weight=weights)

    best_val_accuracy = 0
    best_epoch = 0
    loss_history = []
    val_acc_history = []

    for epoch in range(NUM_EPOCHS):
        train_loss = train_model(model, optimizer, criterion, train_loader)
        val_accuracy, _, _ = evaluate_model(model, val_loader)

        loss_history.append(train_loss)
        val_acc_history.append(val_accuracy)

        print(f"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {train_loss:.4f}")
        print(f"Validation Accuracy after epoch {epoch+1}: {val_accuracy:.2f}%")

        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            best_epoch = epoch

    print("\nFinal evaluation on validation set...")
    val_accuracy, y_true, y_pred = evaluate_model(model, val_loader, show_images=True)
    print(f"Final Validation Accuracy: {val_accuracy:.2f}%")
    print(classification_report(y_true, y_pred))

    # ==== PLOT LOSS AND ACCURACY CURVES ====
    plt.figure(figsize=(10, 4))

    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(loss_history) + 1), loss_history, marker='o')
    plt.title(f"{model_name.upper()} - Training Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(val_acc_history) + 1), val_acc_history, marker='s', color='orange')
    plt.title(f"{model_name.upper()} - Validation Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# glaucoma_diagnosis_ml.py (WITH AUC SCORE)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import transforms, models
from sklearn.metrics import classification_report, roc_auc_score
import pandas as pd
import matplotlib.pyplot as plt
import os
from PIL import Image
import numpy as np
from collections import Counter
import random

# ==== CONFIGURATION ====
BATCH_SIZE = 8
NUM_EPOCHS = 40
LEARNING_RATE = 1e-6
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==== DATA TRANSFORMATIONS ====
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(25),
    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ==== CUSTOM DATASET CLASS ====
class FundusDataset(Dataset):
    def __init__(self, expert_dir, labels_dir, transform=None):
        self.expert_dir = expert_dir
        self.labels_dir = labels_dir
        self.transform = transform
        self.samples = self._prepare_samples()

    def _prepare_samples(self):
        samples = []
        for eye_side, excel_file in zip(['OD', 'OS'], ['patient_data_od.xlsx', 'patient_data_os.xlsx']):
            df = pd.read_excel(os.path.join(self.labels_dir, excel_file))
            for i, row in df.iterrows():
                diagnosis = row['Diagnosis']
                if pd.isna(diagnosis) or diagnosis == 2:
                    continue
                label = 0 if diagnosis == 0 else 1
                filename = f"Opht_cont_RET{i+1:03d}{eye_side}.jpg"
                img_path = os.path.join(self.expert_dir, filename)
                if os.path.exists(img_path):
                    samples.append((img_path, label))
        print("Contoured Label counts:", Counter([lbl for _, lbl in samples]))
        return samples

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        raw_image = image.copy()
        if self.transform:
            image = self.transform(image)
        return image, label, raw_image, os.path.basename(img_path)

# ==== CUSTOM COLLATE FUNCTIONS ====
def collate_fn_train(batch):
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    images = torch.stack(images, dim=0)
    labels = torch.tensor(labels)
    return images, labels

def collate_fn_eval(batch):
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    raw_imgs = [item[2] for item in batch]
    filenames = [item[3] for item in batch]
    images = torch.stack(images, dim=0)
    labels = torch.tensor(labels)
    return images, labels, raw_imgs, filenames

# ==== DATASET LOADING ====
full_dataset = FundusDataset(
    expert_dir="/content/ExpertSegmentations",
    labels_dir="/content/ClinicalData",
    transform=transform
)

print(f"Total contoured samples: {len(full_dataset)}")

# Split 80% train, 20% validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_train)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_eval)

# ==== MODEL ARCHITECTURES ====
def get_model(model_name="resnet18"):
    if model_name == "resnet18":
        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        for name, param in model.named_parameters():
            if "layer4" in name or "fc" in name:
                param.requires_grad = True
            else:
                param.requires_grad = False
        model.fc = nn.Linear(model.fc.in_features, 2)
    elif model_name == "efficientnet_b0":
        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)
        for name, param in model.named_parameters():
            if "features.6" in name or "classifier.1" in name:
                param.requires_grad = True
            else:
                param.requires_grad = False
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)
    else:
        raise ValueError("Unsupported model architecture")
    return model.to(DEVICE)

# ==== TRAINING FUNCTION ====
def train_model(model, optimizer, criterion, loader):
    model.train()
    running_loss = 0
    for images, labels in loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    return running_loss / len(loader)

# ==== EVALUATION FUNCTION ====
def evaluate_model(model, loader, show_images=False):
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    display_data = []
    prob_scores = []

    with torch.no_grad():
        for images, labels, raw_imgs, filenames in loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            probs = torch.softmax(outputs, dim=1)[:, 1]  # probability of class 1

            correct += (preds == labels).sum().item()
            total += labels.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            prob_scores.extend(probs.cpu().numpy())
            display_data.append((raw_imgs[0], filenames[0], preds.item(), labels.item()))

    accuracy = 100 * correct / total
    try:
        auc_score = roc_auc_score(all_labels, prob_scores)
    except:
        auc_score = None

    if show_images:
        print("\nPrediction results on validation set:")
        for i, (img, fname, pred, true) in enumerate(display_data):
            plt.imshow(img)
            plt.axis('off')
            plt.title(f"{fname}: Predicted={pred}, Actual={true}, {'✅' if pred==true else '❌'}")
            plt.show()

    return accuracy, all_labels, all_preds, auc_score

# ==== MAIN TRAINING AND EVALUATION ====
for model_name in ["resnet18", "efficientnet_b0"]:
    print(f"\nTraining {model_name.upper()} on contoured images (80% train)...")
    model = get_model(model_name)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    weights = torch.tensor([1.0, 2.0]).to(DEVICE)
    criterion = nn.CrossEntropyLoss(weight=weights)

    best_val_accuracy = 0
    best_epoch = 0
    loss_history = []
    val_acc_history = []

    for epoch in range(NUM_EPOCHS):
        train_loss = train_model(model, optimizer, criterion, train_loader)
        val_accuracy, _, _, _ = evaluate_model(model, val_loader)

        loss_history.append(train_loss)
        val_acc_history.append(val_accuracy)

        print(f"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {train_loss:.4f}")
        print(f"Validation Accuracy after epoch {epoch+1}: {val_accuracy:.2f}%")

        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            best_epoch = epoch

    print("\nFinal evaluation on validation set...")
    val_accuracy, y_true, y_pred, auc_score = evaluate_model(model, val_loader, show_images=True)
    print(f"Final Validation Accuracy: {val_accuracy:.2f}%")
    print(classification_report(y_true, y_pred))
    if auc_score is not None:
        print(f"AUC Score: {auc_score:.4f}")
    else:
        print("AUC Score could not be computed (check label balance).")

    # ==== PLOT LOSS AND ACCURACY CURVES ====
    plt.figure(figsize=(10, 4))

    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(loss_history) + 1), loss_history, marker='o')
    plt.title(f"{model_name.upper()} - Training Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(val_acc_history) + 1), val_acc_history, marker='s', color='orange')
    plt.title(f"{model_name.upper()} - Validation Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.grid(True)

    plt.tight_layout()
    plt.show()
